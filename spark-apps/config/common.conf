
app {
  name = "smartstar"
  version = "1.0.0"
  description = "SmartStar Data Platform"
  organization = "SmartStar Team"
}

# Shared Spark configuration
spark {
  # Application naming
  app-name = ${app.name}"-"${?MODULE_NAME}"-"${environment}

  # Common serialization settings
  serializer = "org.apache.spark.serializer.KryoSerializer"

  kryo {
    buffer = "64k"
    buffer-max = "64m"
    registration-required = false
    # Register common classes used across all modules
    registrator = "com.smartstar.common.serialization.SmartStarKryoRegistrator"
  }

  # Common SQL settings
  sql {
    adaptive {
      enabled = true
      coalesce-partitions = true
      skew-join = true
      local-shuffle-reader = true
    }

    execution {
      arrow {
        pyspark-enabled = true
        max-records-per-batch = 10000
      }
    }

    # Catalog configuration
    catalog {
      spark_catalog {
        type = "hive"
      }
    }
  }

  # Common storage settings
  storage {
    level = "MEMORY_AND_DISK_SER"
    fraction = 0.6
    safe-fraction = 0.9
  }

  # Common network settings
  network {
    timeout = "120s"
    max-retries = 3
    retry-wait = "1s"
  }

  # Common checkpoint configuration
  checkpoint {
    compress = true
    eager = false
  }
}

# Shared database configuration
database {
  driver = "org.postgresql.Driver"
  connection-pool-size = 10
  connection-timeout = "30s"
  idle-timeout = "10m"
  leak-detection-threshold = "60s"
  auto-commit = false
}

# Shared Kafka configuration
kafka {
  group-id-prefix = "smartstar"
  auto-offset-reset = "earliest"
  session-timeout = "30s"
  heartbeat-interval = "3s"
  enable-auto-commit = true
  auto-commit-interval = "1s"

  # Common consumer settings
  consumer {
    fetch-min-bytes = 1024
    fetch-max-wait = "500ms"
    max-partition-fetch-bytes = 1048576
  }

  # Common producer settings
  producer {
    acks = "1"
    retries = 3
    max-in-flight-requests-per-connection = 5
    compression-type = "snappy"
  }
}

# Shared storage configuration
storage {
  formats {
    input = "parquet"
    output = "delta"
    intermediate = "parquet"
  }
  compression = "snappy"
  write-mode = "overwrite"

  # Common paths structure
  paths {
    raw = ${storage.base-path}"/raw"
    processed = ${storage.base-path}"/processed"
    curated = ${storage.base-path}"/curated"
    temp = ${storage.base-path}"/temp"
    checkpoints = ${storage.base-path}"/checkpoints"
    failed = ${storage.base-path}"/failed"
  }
}

# Shared monitoring configuration
monitoring {
  metrics {
    enabled = true
    namespace = "smartstar"
    reporting-interval = "30s"

    # Common metrics
    custom-metrics = [
      "records-processed",
      "processing-time",
      "error-rate",
      "data-quality-score"
    ]
  }

  health-check {
    enabled = true
    interval = "60s"
    timeout = "10s"
  }

  logging {
    level = "INFO"
    pattern = "%d{yyyy-MM-dd HH:mm:ss} %-5level [%thread] %logger{36} - %msg%n"

    # Common loggers
    loggers {
      "com.smartstar" = "DEBUG"
      "org.apache.spark" = "WARN"
      "org.apache.hadoop" = "WARN"
      "org.apache.kafka" = "WARN"
      "io.delta" = "INFO"
    }
  }
}

# Data quality configuration (shared across modules)
data-quality {
  enabled = true
  fail-on-error = false

  # Common validation rules
  rules {
    null-check = true
    format-validation = true
    range-validation = true
    custom-validation = true
  }

  # Thresholds
  thresholds {
    error-rate = 0.05      # 5% error rate threshold
    completeness = 0.95    # 95% completeness threshold
    uniqueness = 0.98      # 98% uniqueness threshold
  }
}