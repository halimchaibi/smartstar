# Module identification
module {
  name = "ingestion"
  description = "Data Ingestion Module"
  version = "1.0.0"
}

# Ingestion-specific Spark settings
spark {
  # Ingestion typically needs more shuffle partitions for initial data processing
  sql {
    shuffle-partitions = ${?INGESTION_SHUFFLE_PARTITIONS}
    adaptive {
      # More aggressive coalescing for ingestion workloads
      advisory-partition-size = "256MB"
    }
  }

  # Streaming specific settings for ingestion
  streaming {
    checkpoint-location = ${storage.datalake-env-path}"bronze/_checkpoints"

    # Ingestion-specific streaming settings
    trigger {
      processing-time = "30s"
      once = false
    }

    # State management
    state-store {
      provider-class = "org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider"
    }
  }
}

# Ingestion-specific Kafka settings
kafka {
  # Ingestion typically uses larger consumer groups
  consumer {
    max-poll-records = 5000
    fetch-min-bytes = 65536
    auto-offset-reset = "earliest"
  }

  # Topic configuration for ingestion
  topics {
    input = "sensors.temperature,sensors.motion,sensors.air_quality"
  }
}

# Ingestion-specific storage paths
storage {
  paths {
    datalake = ${storage.datalake-env-path}"bronze/sensors"
  }
}