include "common.conf"

environment = "development"

spark {
  master = "local[*]"
  executor {
    memory = "2g"
    cores = 2
  }
  driver {
    memory = "1g"
  }
  dynamic-allocation {
    enabled = false
    max-executors = 2
    min-executors = 1
  }
  sql {
    shuffle-partitions = 8
  }
  # Hadoop Configuration for S3/MinIO
  hadoop {
    fs {
      s3a {
        path.style.access = "true"
        impl = "org.apache.hadoop.fs.s3a.S3AFileSystem"
        access.key = "minioadmin"
        secret.key = "minioadmin"
        # Default for Docker, override with MINIO_ENDPOINT for local
        endpoint = "http://smartstar-minio:9000/"
        endpoint = ${?MINIO_ENDPOINT}
        connection.ssl.enabled = false
      }
    }
  }
}

kafka {
  # Default for Docker, override with KAFKA_BOOTSTRAP_SERVERS for local
  bootstrap-servers = "smartstar-kafka:9092"
  bootstrap-servers = ${?KAFKA_BOOTSTRAP_SERVERS}
  group-id = "smartstar-development"
  topics = "sensors.temperature,sensors.motion,sensors.air_quality"
  checkpoint-location = ${storage.datalake.base-url}${environment}"/bronze/_checkpoints"
  starting-offsets = "earliest"
}

storage {
  datalake {
    s3-endpoint = "http://smartstar-minio:9000"
    s3-endpoint = ${?MINIO_ENDPOINT}
    base-url = "s3a://smartstar/"
    output = ${storage.datalake.base-url}${environment}"/bronze/sensors"
    checkpoint-output = ${storage.datalake.base-url}${environment}"/bronze/_checkpoints"
  }
  paths {
    logs = "/tmp/smartstar/dev/logs"
    debug = "/tmp/smartstar/dev/debug"
  }
}

database {
  url = "jdbc:h2:mem:devdb"
  username = "dev"
  password = "dev"
  driver = "org.h2.Driver"
  connection-pool-size = 3
}